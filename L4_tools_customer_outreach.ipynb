{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royam0820/crewai/blob/main/L4_tools_customer_outreach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbWoGOis4KoG"
      },
      "source": [
        "# Tools for a Customer Outreach Campaign\n",
        "\n",
        "This Jupyter notebook outlines a **customer outreach campaign using AI agents**. It leverages the crewai library to create and manage AI **agents responsible for identifying and nurturing high-value leads through personalized communications**.\n",
        "\n",
        "The workflow involves:\n",
        "- profiling potential leads and\n",
        "- crafting targeted outreach campaigns.\n",
        "\n",
        "\n",
        "In this lesson, you will learn more about Tools. You'll focus on three key elements of Tools:\n",
        "- Versatility\n",
        "- Fault Tolerance\n",
        "- Caching"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library Installation"
      ],
      "metadata": {
        "id": "iOpkgTmgvnp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai==0.28.8\n",
        "!pip install crewai_tools==0.1.6\n",
        "!pip install langchain_community==0.0.29 # this is formatted as code\n",
        "!pip install utils"
      ],
      "metadata": {
        "id": "GtFqlq-UN6uJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f238281-93ae-484e-ed52-28c76a8f0bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai==0.28.8\n",
            "  Downloading crewai-0.28.8-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m61.4/61.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m61.4/61.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m669.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from crewai==0.28.8) (1.4.4)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai==0.28.8) (8.1.7)\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.103-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting instructor<0.6.0,>=0.5.2 (from crewai==0.28.8)\n",
            "  Downloading instructor-0.5.2-py3-none-any.whl (33 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<2.0.0,>=1.13.3 (from crewai==0.28.8)\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.24.0-py3-none-any.whl (16 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai==0.28.8) (2.7.1)\n",
            "Collecting python-dotenv==1.0.0 (from crewai==0.28.8)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.12.25 in /usr/local/lib/python3.10/dist-packages (from crewai==0.28.8) (2023.12.25)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.12.3)\n",
            "Collecting chromadb<0.6.0,>=0.5.0 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.51.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading gptcache-0.1.43-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai<0.0.6,>=0.0.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
            "Collecting posthog<4.0.0,>=3.0.2 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (13.7.1)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /usr/local/lib/python3.10/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.0.30)\n",
            "Collecting tiktoken<0.6.0,>=0.5.2 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai==0.28.8) (3.9.5)\n",
            "Collecting docstring-parser<0.16,>=0.15 (from instructor<0.6.0,>=0.5.2->crewai==0.28.8)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai==0.28.8) (8.3.0)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai==0.28.8) (0.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (6.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.52 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading langsmith-0.1.59-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (2.31.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.13.3->crewai==0.28.8)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (4.11.0)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.24.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (3.20.3)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (2.18.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai==0.28.8) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai==0.28.8) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai==0.28.8) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai==0.28.8) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai==0.28.8) (1.9.4)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai==0.28.8) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.2.1)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.63.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (1.14.1)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (24.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.0.4)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (5.3.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai==0.28.8) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai==0.28.8)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai==0.28.8)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (3.18.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging>=14.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai==0.28.8) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai==0.28.8) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3.0.0,>=2.0.27->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.0.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.48.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.7.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.13.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.2)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.12)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (67.7.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.20.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.1.5)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of fastapi-cli to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading fastapi_cli-0.0.2-py3-none-any.whl (9.1 kB)\n",
            "Collecting fastapi>=0.95.2 (from chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2023.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.6.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.5.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.3.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=faeb79e08df39fb9fe34f87d29985c9e2554f440e7951dd1bf572793eec1aa71\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: schema, pypika, monotonic, mmh3, websockets, uvloop, python-dotenv, pysbd, pypdf, packaging, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, mypy-extensions, Mako, jsonpointer, importlib-metadata, humanfriendly, httptools, h11, docstring-parser, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, marshmallow, jsonpatch, httpcore, gptcache, coloredlogs, alembic, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, langsmith, kubernetes, httpx, fastapi, dataclasses-json, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openai, langchain-core, opentelemetry-instrumentation-fastapi, langchain-text-splitters, langchain-openai, langchain-community, instructor, langchain, chromadb, embedchain, crewai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "  Attempting uninstall: docstring-parser\n",
            "    Found existing installation: docstring_parser 0.16\n",
            "    Uninstalling docstring_parser-0.16:\n",
            "      Successfully uninstalled docstring_parser-0.16\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.5.0 coloredlogs-15.0.1 crewai-0.28.8 dataclasses-json-0.6.6 deprecated-1.2.14 docstring-parser-0.15 embedchain-0.1.103 fastapi-0.110.3 gptcache-0.1.43 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-7.0.0 instructor-0.5.2 jsonpatch-1.33 jsonpointer-2.4 kubernetes-29.0.0 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-openai-0.0.5 langchain-text-splitters-0.0.2 langsmith-0.1.59 marshmallow-3.21.2 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.18.0 openai-1.30.1 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-exporter-otlp-proto-http-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 orjson-3.10.3 overrides-7.7.0 packaging-23.2 posthog-3.5.0 pypdf-4.2.0 pypika-0.48.9 pysbd-0.3.4 python-dotenv-1.0.0 schema-0.7.7 starlette-0.37.2 tiktoken-0.5.2 typing-inspect-0.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement crewai_tools--0.1.6 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for crewai_tools--0.1.6\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting langchain_community==0.0.29\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (0.6.6)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (0.1.52)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (0.1.59)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.0.29) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29) (2.7.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (3.10.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community==0.0.29) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community==0.0.29) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community==0.0.29) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community==0.0.29) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.29) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.29) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29) (2.18.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (1.0.0)\n",
            "Installing collected packages: langchain_community\n",
            "  Attempting uninstall: langchain_community\n",
            "    Found existing installation: langchain-community 0.0.38\n",
            "    Uninstalling langchain-community-0.0.38:\n",
            "      Successfully uninstalled langchain-community-0.0.38\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.1.20 requires langchain-community<0.1,>=0.0.38, but you have langchain-community 0.0.29 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain_community-0.0.29\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: utils\n",
            "  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13906 sha256=9ee25cd3bab7f5ea6cc35323a19f0dbb7cb6b32b58dbfae6f27e3a2a29aa2f71\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\n",
            "Successfully built utils\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RRmDXLDrvs-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Warnings Suppression"
      ],
      "metadata": {
        "id": "wV-o9NVAvtTj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "_LQ5_lop4KJq"
      },
      "outputs": [],
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxxY8YdZWrbH"
      },
      "source": [
        "- Import libraries, APIs and LLM\n",
        "- [Serper](https://serper.dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Required Classes"
      ],
      "metadata": {
        "id": "ETCB-9Ttv4lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "fx4h25rUv7_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting API Keys"
      ],
      "metadata": {
        "id": "mfDWXizewCYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "serper_api_key = userdata.get(\"SERPER_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "os.environ[\"SERPER_API_KEY\"] = serper_api_key\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-4-turbo'"
      ],
      "metadata": {
        "id": "p708uS7MdUPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60Dz80kCWrbJ"
      },
      "source": [
        "## Defining Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sales Representative\n",
        "The Sales Representative agent is responsible for identifying potential leads."
      ],
      "metadata": {
        "id": "1ajDV6blwP6k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 319,
        "id": "i3E0kNdDWrbJ"
      },
      "outputs": [],
      "source": [
        "sales_rep_agent = Agent(\n",
        "    role=\"Sales Representative\",\n",
        "    goal=\"Identify high-value leads that match \"\n",
        "         \"our ideal customer profile\",\n",
        "    backstory=(\n",
        "        \"As a part of the dynamic sales team at CrewAI, \"\n",
        "        \"your mission is to scour \"\n",
        "        \"the digital landscape for potential leads. \"\n",
        "        \"Armed with cutting-edge tools \"\n",
        "        \"and a strategic mindset, you analyze data, \"\n",
        "        \"trends, and interactions to \"\n",
        "        \"unearth opportunities that others might overlook. \"\n",
        "        \"Your work is crucial in paving the way \"\n",
        "        \"for meaningful engagements and driving the company's growth.\"\n",
        "    ),\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lead Sales Representative\n",
        "\n",
        "The Lead Sales Representative agent nurtures leads through personalized communications."
      ],
      "metadata": {
        "id": "Wp7tUk4fwbv2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 302,
        "id": "FIEGVHeLWrbK"
      },
      "outputs": [],
      "source": [
        "lead_sales_rep_agent = Agent(\n",
        "    role=\"Lead Sales Representative\",\n",
        "    goal=\"Nurture leads with personalized, compelling communications\",\n",
        "    backstory=(\n",
        "        \"Within the vibrant ecosystem of CrewAI's sales department, \"\n",
        "        \"you stand out as the bridge between potential clients \"\n",
        "        \"and the solutions they need.\"\n",
        "        \"By creating engaging, personalized messages, \"\n",
        "        \"you not only inform leads about our offerings \"\n",
        "        \"but also make them feel seen and heard.\"\n",
        "        \"Your role is pivotal in converting interest \"\n",
        "        \"into action, guiding leads through the journey \"\n",
        "        \"from curiosity to commitment.\"\n",
        "    ),\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQpouXWvWrbL"
      },
      "source": [
        "## Creating Tools\n",
        "\n",
        "### crewAI Tools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai_tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xVYEsHD_ZV2i",
        "outputId": "7d2fd516-782b-46c2-ab07-8683b42ec64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai_tools\n",
            "  Downloading crewai_tools-0.2.6-py3-none-any.whl (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from crewai_tools) (4.12.3)\n",
            "Collecting chromadb<0.5.0,>=0.4.22 (from crewai_tools)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docx2txt<0.9,>=0.8 (from crewai_tools)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: embedchain[github,youtube]<0.2.0,>=0.1.85 in /usr/local/lib/python3.10/dist-packages (from crewai_tools) (0.1.103)\n",
            "Collecting lancedb<0.6.0,>=0.5.4 (from crewai_tools)\n",
            "  Downloading lancedb-0.5.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from crewai_tools) (0.1.20)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from crewai_tools) (1.30.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from crewai_tools) (2.7.1)\n",
            "Collecting pyright<2.0.0,>=1.1.350 (from crewai_tools)\n",
            "  Downloading pyright-1.1.363-py3-none-any.whl (18 kB)\n",
            "Collecting pytest<9.0.0,>=8.0.0 (from crewai_tools)\n",
            "  Downloading pytest-8.2.0-py3-none-any.whl (339 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.2/339.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytube<16.0.0,>=15.0.0 (from crewai_tools)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from crewai_tools) (2.31.0)\n",
            "Collecting selenium<5.0.0,>=4.18.1 (from crewai_tools)\n",
            "  Downloading selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools) (2.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (1.2.1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (0.110.3)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (0.29.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (1.25.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (4.11.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools)\n",
            "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (1.18.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (1.24.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (4.66.4)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (1.63.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (4.1.3)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (0.9.4)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (29.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (8.3.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools) (3.10.3)\n",
            "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (1.13.1)\n",
            "INFO: pip is looking at multiple versions of embedchain[github,youtube] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting embedchain[github,youtube]<0.2.0,>=0.1.85 (from crewai_tools)\n",
            "  Downloading embedchain-0.1.102-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.7/192.7 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (1.51.0)\n",
            "Requirement already satisfied: gptcache<0.2.0,>=0.1.43 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (0.1.43)\n",
            "Requirement already satisfied: langchain-openai<0.0.6,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (0.0.5)\n",
            "Collecting pypdf<4.0.0,>=3.11.0 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pysbd<0.4.0,>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (0.3.4)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (1.0.0)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (13.7.1)\n",
            "Requirement already satisfied: schema<0.8.0,>=0.7.5 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (0.7.7)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (2.0.30)\n",
            "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (0.5.2)\n",
            "Collecting youtube-transcript-api<0.7.0,>=0.6.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting yt_dlp<2024.0.0,>=2023.11.14 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyGithub<2.0.0,>=1.59.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading PyGithub-1.59.1-py3-none-any.whl (342 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitpython<4.0.0,>=3.1.38 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecation (from lancedb<0.6.0,>=0.5.4->crewai_tools)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pylance==0.9.18 (from lancedb<0.6.0,>=0.5.4->crewai_tools)\n",
            "  Downloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ratelimiter~=1.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools)\n",
            "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
            "Collecting retry>=0.9.2 (from lancedb<0.6.0,>=0.5.4->crewai_tools)\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools) (23.2.0)\n",
            "Collecting semver>=3.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools) (5.3.3)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools) (8.1.7)\n",
            "Requirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.10/dist-packages (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai_tools) (14.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.4->crewai_tools) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.4->crewai_tools) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.4->crewai_tools) (0.6.6)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2.0,>=0.1.4->crewai_tools)\n",
            "  Using cached langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.4->crewai_tools) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.4->crewai_tools) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.4->crewai_tools) (0.1.59)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->crewai_tools) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.12.0->crewai_tools) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->crewai_tools) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->crewai_tools) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.1->crewai_tools) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.1->crewai_tools) (2.18.2)\n",
            "Collecting nodeenv>=1.6.0 (from pyright<2.0.0,>=1.1.350->crewai_tools)\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools) (2024.2.2)\n",
            "Collecting trio~=0.17 (from selenium<5.0.0,>=4.18.1->crewai_tools)\n",
            "  Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.7/467.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.18.1->crewai_tools)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.4->crewai_tools) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.4->crewai_tools) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.4->crewai_tools) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.4->crewai_tools) (1.9.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (1.3.5)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.4->crewai_tools) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.4->crewai_tools) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools) (0.37.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (3.20.3)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (2.0.4)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (0.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.12.0->crewai_tools) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.12.0->crewai_tools) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (3.2.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.4->crewai_tools) (1.33)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=1.6.0->pyright<2.0.0,>=1.1.350->crewai_tools) (67.7.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (7.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.63.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.24.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools) (0.45b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (2.2.1)\n",
            "Collecting pyjwt[crypto]>=2.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3.0.0,>=2.0.27->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (2023.12.25)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools) (0.20.3)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.18.1->crewai_tools)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3<3,>=1.21.1->requests<3.0.0,>=2.31.0->crewai_tools) (1.7.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools) (0.6.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools) (12.0)\n",
            "Collecting mutagen (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (1.48.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (2.7.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (0.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->crewai_tools) (3.18.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.4->crewai_tools) (2.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (0.1.2)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (42.0.7)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.4->crewai_tools) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (2.22)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools) (0.6.0)\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=f9d5015b329f15ea62bb324f68eed6a9af93f8e282be135b23b2769de7788ffc\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: ratelimiter, docx2txt, brotli, wsproto, smmap, semver, pytube, pytest, pypdf, pyjwt, pycryptodomex, py, pulsar-client, outcome, nodeenv, mutagen, deprecation, yt_dlp, youtube-transcript-api, trio, retry, pyright, pynacl, pylance, gitdb, trio-websocket, lancedb, gitpython, selenium, PyGithub, langchain-community, chromadb, embedchain, crewai_tools\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "  Attempting uninstall: pypdf\n",
            "    Found existing installation: pypdf 4.2.0\n",
            "    Uninstalling pypdf-4.2.0:\n",
            "      Successfully uninstalled pypdf-4.2.0\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.0.29\n",
            "    Uninstalling langchain-community-0.0.29:\n",
            "      Successfully uninstalled langchain-community-0.0.29\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.5.0\n",
            "    Uninstalling chromadb-0.5.0:\n",
            "      Successfully uninstalled chromadb-0.5.0\n",
            "  Attempting uninstall: embedchain\n",
            "    Found existing installation: embedchain 0.1.103\n",
            "    Uninstalling embedchain-0.1.103:\n",
            "      Successfully uninstalled embedchain-0.1.103\n",
            "Successfully installed PyGithub-1.59.1 brotli-1.1.0 chromadb-0.4.24 crewai_tools-0.2.6 deprecation-2.1.0 docx2txt-0.8 embedchain-0.1.102 gitdb-4.0.11 gitpython-3.1.43 lancedb-0.5.7 langchain-community-0.0.38 mutagen-1.47.0 nodeenv-1.8.0 outcome-1.3.0.post0 pulsar-client-3.5.0 py-1.11.0 pycryptodomex-3.20.0 pyjwt-2.8.0 pylance-0.9.18 pynacl-1.5.0 pypdf-3.17.4 pyright-1.1.363 pytest-8.2.0 pytube-15.0.0 ratelimiter-1.2.0.post0 retry-0.9.2 selenium-4.21.0 semver-3.0.2 smmap-5.0.1 trio-0.25.1 trio-websocket-0.11.1 wsproto-1.2.0 youtube-transcript-api-0.6.2 yt_dlp-2023.12.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chromadb"
                ]
              },
              "id": "adbc55e653554f2784d28bce8c3d4198"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "sdE5oCZGWrbL"
      },
      "outputs": [],
      "source": [
        "from crewai_tools import DirectoryReadTool, \\\n",
        "                         FileReadTool, \\\n",
        "                         SerperDevTool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "mUE73kT-WrbM"
      },
      "outputs": [],
      "source": [
        "directory_read_tool = DirectoryReadTool(directory='./instructions')\n",
        "file_read_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIu0cUbgWrbM"
      },
      "source": [
        "### Custom Tool\n",
        "- Create a custom tool using crewAi's [BaseTool](https://docs.crewai.com/core-concepts/Tools/#subclassing-basetool) class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "pVUGfcTjWrbN"
      },
      "outputs": [],
      "source": [
        "from crewai_tools import BaseTool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGAypcABWrbN"
      },
      "source": [
        "- Every Tool needs to have a `name` and a `description`.\n",
        "- For simplicity and classroom purposes, `SentimentAnalysisTool` will return `positive` for every text.\n",
        "- When running locally, you can customize the code with your logic in the `_run` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 149,
        "id": "dc4PLhwaWrbN"
      },
      "outputs": [],
      "source": [
        "class SentimentAnalysisTool(BaseTool):\n",
        "    name: str =\"Sentiment Analysis Tool\"\n",
        "    description: str = (\"Analyzes the sentiment of text \"\n",
        "         \"to ensure positive and engaging communication.\")\n",
        "\n",
        "    def _run(self, text: str) -> str:\n",
        "        # Your custom code tool goes here\n",
        "        return \"positive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "9GfXUEZ6WrbN"
      },
      "outputs": [],
      "source": [
        "sentiment_analysis_tool = SentimentAnalysisTool()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbLYCZwLWrbO"
      },
      "source": [
        "## Defining Tasks\n",
        "\n",
        "- The Lead Profiling Task is using crewAI Tools."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lead Profiling Task\n",
        "\n",
        "This task involves the Sales Representative agent profiling potential leads.\n",
        "\n",
        "The Lead Profiling Task is using crewAI Tools."
      ],
      "metadata": {
        "id": "0X4T2gKqwvPA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 455,
        "id": "sxsCfnA_WrbO"
      },
      "outputs": [],
      "source": [
        "lead_profiling_task = Task(\n",
        "    description=(\n",
        "        \"Conduct an in-depth analysis of {lead_name}, \"\n",
        "        \"a company in the {industry} sector \"\n",
        "        \"that recently showed interest in our solutions. \"\n",
        "        \"Utilize all available data sources \"\n",
        "        \"to compile a detailed profile, \"\n",
        "        \"focusing on key decision-makers, recent business \"\n",
        "        \"developments, and potential needs \"\n",
        "        \"that align with our offerings. \"\n",
        "        \"This task is crucial for tailoring \"\n",
        "        \"our engagement strategy effectively.\\n\"\n",
        "        \"Don't make assumptions and \"\n",
        "        \"only use information you absolutely sure about.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A comprehensive report on {lead_name}, \"\n",
        "        \"including company background, \"\n",
        "        \"key personnel, recent milestones, and identified needs. \"\n",
        "        \"Highlight potential areas where \"\n",
        "        \"our solutions can provide value, \"\n",
        "        \"and suggest personalized engagement strategies.\"\n",
        "    ),\n",
        "    tools=[directory_read_tool, file_read_tool, search_tool],\n",
        "    agent=sales_rep_agent,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Personalized Outreach Task\n",
        "\n",
        "This task involves the Lead Sales Representative agent crafting personalized outreach campaigns.\n",
        "\n",
        "The Personalized Outreach Task is using your custom Tool `SentimentAnalysisTool`, as well as crewAI's `SerperDevTool` (search_tool).\n"
      ],
      "metadata": {
        "id": "XiyHTR0Ew9FR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 506,
        "id": "ekp5PerfWrbP"
      },
      "outputs": [],
      "source": [
        "personalized_outreach_task = Task(\n",
        "    description=(\n",
        "        \"Using the insights gathered from \"\n",
        "        \"the lead profiling report on {lead_name}, \"\n",
        "        \"craft a personalized outreach campaign \"\n",
        "        \"aimed at {key_decision_maker}, \"\n",
        "        \"the {position} of {lead_name}. \"\n",
        "        \"The campaign should address their recent {milestone} \"\n",
        "        \"and how our solutions can support their goals. \"\n",
        "        \"Your communication must resonate \"\n",
        "        \"with {lead_name}'s company culture and values, \"\n",
        "        \"demonstrating a deep understanding of \"\n",
        "        \"their business and needs.\\n\"\n",
        "        \"Don't make assumptions and only \"\n",
        "        \"use information you absolutely sure about.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A series of personalized email drafts \"\n",
        "        \"tailored to {lead_name}, \"\n",
        "        \"specifically targeting {key_decision_maker}.\"\n",
        "        \"Each draft should include \"\n",
        "        \"a compelling narrative that connects our solutions \"\n",
        "        \"with their recent achievements and future goals. \"\n",
        "        \"Ensure the tone is engaging, professional, \"\n",
        "        \"and aligned with {lead_name}'s corporate identity.\"\n",
        "    ),\n",
        "    tools=[sentiment_analysis_tool, search_tool],\n",
        "    agent=lead_sales_rep_agent,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztRBwSwVWrbP"
      },
      "source": [
        "## Assembling the Crew and Executing the Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 183,
        "id": "60aiFX3_WrbP"
      },
      "outputs": [],
      "source": [
        "crew = Crew(\n",
        "    agents=[sales_rep_agent,\n",
        "            lead_sales_rep_agent],\n",
        "\n",
        "    tasks=[lead_profiling_task,\n",
        "           personalized_outreach_task],\n",
        "\n",
        "    verbose=2,\n",
        "\tmemory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5x-j-pkWrbP"
      },
      "source": [
        "## Inputs and Execution\n",
        "\n",
        "**Note**: LLMs can provide different outputs for they same input, so what you get might be different than what you see in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 166,
        "id": "hpvL4nEYWrbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0240fa90-b9ff-4c99-fef5-8e2cf9996faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Sales Representative\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Conduct an in-depth analysis of DeepLearningAI, a company in the Online Learning Platform sector that recently showed interest in our solutions. Utilize all available data sources to compile a detailed profile, focusing on key decision-makers, recent business developments, and potential needs that align with our offerings. This task is crucial for tailoring our engagement strategy effectively.\n",
            "Don't make assumptions and only use information you absolutely sure about.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To begin compiling a detailed profile on DeepLearningAI, I should start by searching the internet to gather preliminary information about the company, its key decision-makers, recent developments, and its potential needs.\n",
            "\n",
            "Action: Search the internet\n",
            "Action Input: {\"search_query\": \"DeepLearningAI company profile\"}\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: Deeplearning.ai - Crunchbase Company Profile & Funding\n",
            "Link: https://www.crunchbase.com/organization/deeplearning-ai\n",
            "Snippet: Deeplearning.ai is company that explores the frontier of AI. The company is founded by Andrew Ng, the former Chief Scientist of Baidu and the current Chairman ...\n",
            "---\n",
            "Title: DeepLearning.AI - LinkedIn\n",
            "Link: https://www.linkedin.com/company/deeplearningai\n",
            "Snippet: DeepLearning.AI is making a world-class AI education accessible to people around the globe. DeepLearning.AI was founded by Andrew Ng, a global leader in AI.\n",
            "---\n",
            "Title: DEEPLEARNING.AI LLC Company Profile | Palo Alto, CA\n",
            "Link: https://www.dnb.com/business-directory/company-profiles.deeplearningai_llc.7cb525da4ad45b067062d87d5fbcad0b.html\n",
            "Snippet: Find company research, competitor information, contact details & financial data for DEEPLEARNING.AI LLC of Palo Alto, CA. Get the latest business insights ...\n",
            "---\n",
            "Title: Deeplearning.ai company information, funding & investors\n",
            "Link: https://app.dealroom.co/companies/deeplearning_ai\n",
            "Snippet: Deeplearning.ai, deeplearningai is company that explores the frontier of ai. Here you'll find information about their funding, investors and team.\n",
            "---\n",
            "Title: DeepLearning.AI: Start or Advance Your Career in AI\n",
            "Link: https://www.deeplearning.ai/\n",
            "Snippet: Learn the skills to start or advance your AI career | World-class education | Hands-on training | Collaborative community of peers and mentors.\n",
            "---\n",
            "Title: DeepLearning.AI - Overview, News & Similar companies - ZoomInfo\n",
            "Link: https://www.zoominfo.com/c/deeplearningai-inc/462132321\n",
            "Snippet: View DeepLearning.AI (www.deeplearning.ai) location in California, United States , revenue, industry and description. Find related and similar companies as ...\n",
            "---\n",
            "Title: Top Deep Learning Companies - May 2024 Reviews - GoodFirms\n",
            "Link: https://www.goodfirms.co/artificial-intelligence/deep-learning\n",
            "Snippet: List of Top AI Companies for Deep Learning · SoluLab · Simublade · OpenXcell · KitRUM · Altamira · Outsource Bigdata · 6omb AI · Need assistance in finding the best ...\n",
            "---\n",
            "Title: deeplearning.ai: Revenue, Competitors, Alternatives - Growjo\n",
            "Link: https://growjo.com/company/deeplearning.ai\n",
            "Snippet: deeplearning.ai top competitors are TruthMD, Atrium and Bluestone PIM and they have annual revenue of $62.7M and 346 employees.\n",
            "---\n",
            "Title: DeepLearning.AI - The Org\n",
            "Link: https://theorg.com/org/deeplearning-ai\n",
            "Snippet: DeepLearning.AI is making a world-class AI education accessible to people around the globe. DeepLearning.AI was founded by Andrew Ng, a global leader in AI.\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: The search results provide several promising sources for comprehensive information about DeepLearningAI, including company background, key personnel, and recent milestones. I should begin by exploring the Crunchbase profile for detailed company insights, funding, and founder information.\n",
            "\n",
            "Action: Search the internet\n",
            "Action Input: {\"search_query\": \"Deeplearning.ai Crunchbase profile\"}\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: Deeplearning.ai - Crunchbase Company Profile & Funding\n",
            "Link: https://www.crunchbase.com/organization/deeplearning-ai\n",
            "Snippet: Deeplearning.ai is company that explores the frontier of AI. The company is founded by Andrew Ng, the former Chief Scientist of Baidu and the current Chairman ...\n",
            "---\n",
            "Title: Andrew Ng - Founder and CEO @ Deeplearning.ai - Crunchbase\n",
            "Link: https://www.crunchbase.com/person/andrew-ng\n",
            "Snippet: Andrew Ng is the Founder and CEO of Deeplearning.ai and Landing AI. He is also a Co-founder and Chairman at Coursera, an Adjunct Professor of Computer ...\n",
            "---\n",
            "Title: About - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/about/\n",
            "Snippet: DeepLearning.AI is an education technology company that is empowering the global workforce to build an AI-powered future through world-class education, hands-on ...\n",
            "---\n",
            "Title: DeepLearning.AI Online Courses - Coursera\n",
            "Link: https://www.coursera.org/deeplearning-ai\n",
            "Snippet: DeepLearning.AI is an education technology company that develops a global community of AI talent. DeepLearning.AI's expert-led educational experiences ...\n",
            "---\n",
            "Title: Competera - Crunchbase Company Profile & Funding | Deep ...\n",
            "Link: https://www.pinterest.com/pin/competera-crunchbase-company-profile-funding-in-2023--372532200440665379/\n",
            "Snippet: Competera enables retailers and brands to increase customer trust by setting and maintaining optimal price positions on a real-time basis.\n",
            "---\n",
            "Title: Mistral AI - LinkedIn\n",
            "Link: https://www.linkedin.com/company/mistralai/\n",
            "Snippet: Fast, open-source and secure language models. Facilitated specialisation of models on business use-cases, leveraging private data and usage feedback.\n",
            "---\n",
            "Title: Generative AI Startups Raise Hundreds of Millions in Funding\n",
            "Link: https://www.deeplearning.ai/the-batch/generative-ai-startups-raise-hundreds-of-millions-in-funding/\n",
            "Snippet: What's new: Venture capitalists are betting hundreds of millions of dollars on startups that use AI to generate images, text, and more, Wired ...\n",
            "---\n",
            "Title: Geoffrey Hinton (@geoffreyhinton) / X\n",
            "Link: https://twitter.com/geoffreyhinton?lang=en\n",
            "Snippet: Opens profile photo. Geoffrey Hinton ... data and her work opened the floodgates for deep learning. ... investors evaluating investments in AI technologies.\n",
            "---\n",
            "Title: Stanislav Protopopov on LinkedIn: Crunchbase + AI/ML = to find ...\n",
            "Link: https://www.linkedin.com/posts/s-protopopov_crunchbase-aiml-to-find-russian-speaking-activity-7184841547748679680-3Du7\n",
            "Snippet: After diving deep into data preprocessing, I formulated a compelling problem statement that could make a real difference. Here's the catch ...\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: The Crunchbase profile snippet highlighted that DeepLearningAI is a company focusing on the frontier of AI, founded by Andrew Ng. This provides a good start but more detailed insights are needed about the company’s key personnel, recent milestones, and potential needs. I should now explore the detailed company profile and founder information directly from the Crunchbase website.\n",
            "\n",
            "Action: Search the internet\n",
            "Action Input: {\"search_query\": \"Deeplearning.ai Crunchbase company profile detailed\"}\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: Deeplearning.ai - Crunchbase Company Profile & Funding\n",
            "Link: https://www.crunchbase.com/organization/deeplearning-ai\n",
            "Snippet: Details. Deeplearning.ai is company that explores the frontier of AI. The company is founded by Andrew Ng, the former Chief Scientist of Baidu and the current ...\n",
            "---\n",
            "Title: Deeplearning.ai - Crunchbase\n",
            "Link: https://www.crunchbase.com/organization/deeplearning-ai/org_similarity_overview\n",
            "Snippet: Deeplearning.ai is company that explores the frontier of AI.\n",
            "---\n",
            "Title: About - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/about/\n",
            "Snippet: DeepLearning.AI is an education technology company that is empowering the global workforce to build an AI-powered future through world-class education, hands-on ...\n",
            "---\n",
            "Title: Deeplearning.ai company information, funding & investors\n",
            "Link: https://app.dealroom.co/companies/deeplearning_ai\n",
            "Snippet: Deeplearning.ai, deeplearningai is company that explores the frontier of ai. Here you'll find information about their funding, investors and team.\n",
            "---\n",
            "Title: Christian Tooley on LinkedIn: #ml #agi #ethics #dataprivacy ...\n",
            "Link: https://www.linkedin.com/posts/christiantooley_ml-agi-ethics-activity-6519496796329349120-NEVc?trk=public_profile_like_view\n",
            "Snippet: ... deeplearning.ai. Found it very useful when ... com now to tag yourself on your crunchbase profile, complete the survey, & register for iiF!\n",
            "---\n",
            "Title: DeepLearning.AI - Overview, News & Similar companies - ZoomInfo\n",
            "Link: https://www.zoominfo.com/c/deeplearningai-inc/462132321\n",
            "Snippet: View DeepLearning.AI (www.deeplearning.ai) location in California, United States , revenue, industry and description. Find related and similar companies as ...\n",
            "---\n",
            "Title: Geoffrey Hinton (@geoffreyhinton) / X\n",
            "Link: https://twitter.com/geoffreyhinton?lang=en\n",
            "Snippet: ... its Responsible AI for Startups (RAIS) framework - an open source resource for investors evaluating investments in AI technologies. Show more. 6. 25. 59.\n",
            "---\n",
            "Title: I reverse-engineered a $500M Artificial Intelligence company in one ...\n",
            "Link: https://medium.com/startup-grind/i-reverse-engineered-a-500m-artificial-intelligence-company-in-one-week-heres-the-full-story-d067cef99e1c\n",
            "Snippet: I reverse-engineered a $500M Artificial Intelligence company in one week. Here's the full story. Gianluca Mauro.\n",
            "---\n",
            "Title: Hive AI: AI to Understand, Search, and Generate Content\n",
            "Link: https://thehive.ai/\n",
            "Snippet: Hive's APIs enable developers to integrate pre-trained AI models that address technically challenging content understanding needs into their applications.\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: The detailed search on Crunchbase did not yield further information beyond what was initially found. The snippet repeats the company's focus on AI and its founder. To compile a comprehensive profile on DeepLearningAI, I need to explore other sources like LinkedIn or the company's own website for recent developments and potential needs.\n",
            "\n",
            "Action: Search the internet\n",
            "Action Input: {\"search_query\": \"DeepLearningAI recent developments\"}\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: The Batch | DeepLearning.AI | AI News & Insights\n",
            "Link: https://www.deeplearning.ai/the-batch/\n",
            "Snippet: Weekly AI news for engineers, executives, and enthusiasts.\n",
            "---\n",
            "Title: DeepLearning.AI: Start or Advance Your Career in AI\n",
            "Link: https://www.deeplearning.ai/\n",
            "Snippet: Learn the skills to start or advance your AI career | World-class education | Hands-on training | Collaborative community of peers and mentors.\n",
            "---\n",
            "Title: The Batch - DeepLearning.AI News\n",
            "Link: https://www.deeplearning.ai/the-batch/tag/deeplearning-ai-news/\n",
            "Snippet: Weekly AI news for engineers, executives, and enthusiasts.\n",
            "---\n",
            "Title: Announcing new Deep Learning courses on ... - deeplearning.ai\n",
            "Link: https://www.deeplearning.ai/blog/deeplearning-ai-announcing-new-deep-learning-courses-on-coursera/\n",
            "Snippet: I have been working on three new AI projects, and am thrilled to announce the first one: deeplearning.ai, a project dedicated to disseminating AI knowledge, is ...\n",
            "---\n",
            "Title: Blog - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/blog/\n",
            "Snippet: DeepLearning.AI Blog — Insights, explorations, and success stories from our extended community of AI experts and learners.\n",
            "---\n",
            "Title: Search | The Batch | AI News & Insights - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/search/\n",
            "Snippet: Search relevant articles and resources on The Batch.\n",
            "---\n",
            "Title: Artificial General Intelligence Progress Report - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/the-batch/artificial-general-intelligence-progress-report/\n",
            "Snippet: Similarly, recent progress on LLMs and image generation models has reignited speculation about artificial general intelligence (AGI).\n",
            "---\n",
            "Title: Generative AI with Large Language Models — New Hands ... - AWS\n",
            "Link: https://aws.amazon.com/blogs/aws/generative-ai-with-large-language-models-new-hands-on-course-by-deeplearning-ai-and-aws/\n",
            "Snippet: Generative AI with Large Language Models — New Hands-on Course by DeepLearning.AI and AWS ... Generative AI has taken the world by storm, and we' ...\n",
            "---\n",
            "Title: DeepLearning.AI Online Courses - Coursera\n",
            "Link: https://www.coursera.org/deeplearning-ai\n",
            "Snippet: DeepLearning.AI's expert-led educational experiences provide AI practitioners and non-technical professionals with the necessary tools to go all the way from ...\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: The recent developments search results provide updates on new courses, collaborations, and general news about DeepLearningAI. These insights can be useful to understand their current focus areas and initiatives. To gather more specific information about their potential needs and how our solutions can provide value, I should now look into the details of their new courses and collaborations as mentioned in the links provided.\n",
            "\n",
            "Action: Search the internet\n",
            "Action Input: {\"search_query\": \"DeepLearningAI new courses and collaborations\"}\u001b[0m\u001b[95m \n",
            "\n",
            "\n",
            "Search results: Title: DeepLearning.AI: Start or Advance Your Career in AI\n",
            "Link: https://www.deeplearning.ai/\n",
            "Snippet: Learn the skills to start or advance your AI career | World-class education | Hands-on training | Collaborative community of peers and mentors.\n",
            "---\n",
            "Title: Short Courses | Learn Generative AI from DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/short-courses/\n",
            "Snippet: Take your generative AI skills to the next level with short courses from DeepLearning.AI. Enroll today to learn directly from industry leaders, and practice ...\n",
            "---\n",
            "Title: Machine Learning Specialization - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/courses/machine-learning-specialization/\n",
            "Snippet: New Machine Learning Specialization, an updated foundational program for beginners created by Andrew Ng | Start Your AI Career Today.\n",
            "---\n",
            "Title: Courses - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/courses/\n",
            "Snippet: Our Courses · Introductory · Machine Learning Specialization · Mathematics for Machine Learning and Data Science Specialization · AI for Everyone · AI for Good ...\n",
            "---\n",
            "Title: The Batch | DeepLearning.AI | AI News & Insights\n",
            "Link: https://www.deeplearning.ai/the-batch/\n",
            "Snippet: 🌟 New Course! Enroll in Multi AI Agent Systems ... The Batch AI News and Insights: Multi-agent collaboration ... collaborators gathered in California for two days ...\n",
            "---\n",
            "Title: Pair Programming with a Large Language Model - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/short-courses/pair-programming-llm/\n",
            "Snippet: Learn how LLMs can enhance, debug, and document your code in this new course built in collaboration with Google.\n",
            "---\n",
            "Title: DeepLearning.AI on LinkedIn: A new course built in collaboration ...\n",
            "Link: https://www.linkedin.com/posts/deeplearningai_a-new-course-built-in-collaboration-with-activity-7105212918387904512-uzaq\n",
            "Snippet: A new course built in collaboration with Google Cloud is available starting today! 🎊 Introducing \"Understanding and Applying Text ...\n",
            "---\n",
            "Title: Learning & Education | The Batch - DeepLearning.AI\n",
            "Link: https://www.deeplearning.ai/the-batch/tag/learning-education/\n",
            "Snippet: Three New Courses!: Check out our short courses on Building Systems with the ChatGPT API, LangChain for LLM Application Development, and How Diffusion Models ...\n",
            "---\n",
            "Title: Courses | Andrew Ng\n",
            "Link: https://www.andrewng.org/courses/\n",
            "Snippet: The Machine Learning Specialization is a foundational online program created in collaboration between DeepLearning.AI and Stanford Online. This beginner ...\n",
            "---\n",
            "Title: Announcing the upcoming launch of Introduction to On-Device AI, a ...\n",
            "Link: https://www.instagram.com/deeplearningai/reel/C6t-vTOPVkM/\n",
            "Snippet: It's here! #AndrewNg's new course: Generative AI for Everyone!\n",
            "---\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "\n",
            "Final Answer: DeepLearningAI is an education technology company focused on empowering the global workforce to build an AI-powered future through world-class education and hands-on training. Founded by Andrew Ng, a prominent figure in the AI industry, the company aims to make high-quality AI education accessible globally. Key individuals associated with the company include Andrew Ng, who plays a significant role as the founder.\n",
            "\n",
            "Recent developments at DeepLearningAI include the launch of new courses and collaborations. Notably, they have introduced a Machine Learning Specialization, updated foundational programs for beginners, and courses on Generative AI with hands-on learning experiences. The company has collaborated with prominent tech companies like Google and AWS to enhance these educational offerings.\n",
            "\n",
            "DeepLearningAI's potential needs could include advanced tools and solutions that facilitate scalable online education, sophisticated AI training platforms, and technologies that enhance user engagement and learning outcomes. Our solutions can potentially provide value in these areas by offering AI-driven analytics to understand learner behaviors, personalized learning experiences based on AI insights, and enhanced interactive platforms that support a global audience.\n",
            "\n",
            "To engage effectively with DeepLearningAI, a personalized approach highlighting how our solutions align with their mission of democratizing AI education globally could be adopted. Emphasizing potential collaborations in developing AI-driven educational tools and platforms may also be a strategic way to initiate conversations.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Sales Representative] Task output: DeepLearningAI is an education technology company focused on empowering the global workforce to build an AI-powered future through world-class education and hands-on training. Founded by Andrew Ng, a prominent figure in the AI industry, the company aims to make high-quality AI education accessible globally. Key individuals associated with the company include Andrew Ng, who plays a significant role as the founder.\n",
            "\n",
            "Recent developments at DeepLearningAI include the launch of new courses and collaborations. Notably, they have introduced a Machine Learning Specialization, updated foundational programs for beginners, and courses on Generative AI with hands-on learning experiences. The company has collaborated with prominent tech companies like Google and AWS to enhance these educational offerings.\n",
            "\n",
            "DeepLearningAI's potential needs could include advanced tools and solutions that facilitate scalable online education, sophisticated AI training platforms, and technologies that enhance user engagement and learning outcomes. Our solutions can potentially provide value in these areas by offering AI-driven analytics to understand learner behaviors, personalized learning experiences based on AI insights, and enhanced interactive platforms that support a global audience.\n",
            "\n",
            "To engage effectively with DeepLearningAI, a personalized approach highlighting how our solutions align with their mission of democratizing AI education globally could be adopted. Emphasizing potential collaborations in developing AI-driven educational tools and platforms may also be a strategic way to initiate conversations.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Lead Sales Representative\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Using the insights gathered from the lead profiling report on DeepLearningAI, craft a personalized outreach campaign aimed at Andrew Ng, the CEO of DeepLearningAI. The campaign should address their recent product launch and how our solutions can support their goals. Your communication must resonate with DeepLearningAI's company culture and values, demonstrating a deep understanding of their business and needs.\n",
            "Don't make assumptions and only use information you absolutely sure about.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to ensure the email draft for Andrew Ng is both engaging and resonates with the mission and achievements of DeepLearningAI. The email should emphasize how our solutions can support their recent course launches and collaborations with tech giants like Google and AWS. I should use the sentiment analysis tool to ensure the tone is positive and engaging.\n",
            "\n",
            "Action: Sentiment Analysis Tool\n",
            "Action Input: {\"text\": \"Subject: Empowering DeepLearningAI's Mission through Innovative AI Solutions\\n\\nDear Andrew,\\n\\nI hope this message finds you well. I'm reaching out to celebrate DeepLearningAI's recent successes in launching the new Machine Learning Specialization and updated courses in collaboration with tech leaders like Google and AWS. Your commitment to democratizing AI education aligns perfectly with our mission at CrewAI.\\n\\nAt CrewAI, we specialize in developing AI-driven solutions that enhance online learning experiences. Our tools can provide deep insights into learner behaviors, enabling you to offer more personalized and effective educational programs. Moreover, our collaboration could further innovate your platforms, making AI education even more accessible and impactful across the globe.\\n\\nI would love the opportunity to discuss how our solutions could support DeepLearningAI's goals and contribute to the future of AI education. Are you available for a brief call next week to explore this potential partnership?\\n\\nLooking forward to your thoughts.\\n\\nBest regards,\\n[Your Name]\\nLead Sales Representative, CrewAI\"}\u001b[0m\u001b[95m \n",
            "\n",
            "positive\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: The sentiment analysis confirms that the draft email has a positive tone, which is key for engaging Andrew Ng professionally and warmly. The content of the email effectively connects CrewAI's solutions with the goals and recent achievements of DeepLearningAI, making it a potentially compelling communication. Now, I can finalize the email draft and ensure all details are appropriately personalized and reflect both companies' focus on AI and education.\n",
            "\n",
            "Final Answer:\n",
            "Subject: Empowering DeepLearningAI's Mission through Innovative AI Solutions\n",
            "\n",
            "Dear Andrew,\n",
            "\n",
            "I hope this message finds you well. I'm reaching out to celebrate DeepLearningAI's recent successes in launching the new Machine Learning Specialization and updated courses in collaboration with tech leaders like Google and AWS. Your commitment to democratizing AI education aligns perfectly with our mission at CrewAI.\n",
            "\n",
            "At CrewAI, we specialize in developing AI-driven solutions that enhance online learning experiences. Our tools can provide deep insights into learner behaviors, enabling you to offer more personalized and effective educational programs. Moreover, our collaboration could further innovate your platforms, making AI education even more accessible and impactful across the globe.\n",
            "\n",
            "I would love the opportunity to discuss how our solutions could support DeepLearningAI's goals and contribute to the future of AI education. Are you available for a brief call next week to explore this potential partnership?\n",
            "\n",
            "Looking forward to your thoughts.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Lead Sales Representative, CrewAI\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Lead Sales Representative] Task output: Subject: Empowering DeepLearningAI's Mission through Innovative AI Solutions\n",
            "\n",
            "Dear Andrew,\n",
            "\n",
            "I hope this message finds you well. I'm reaching out to celebrate DeepLearningAI's recent successes in launching the new Machine Learning Specialization and updated courses in collaboration with tech leaders like Google and AWS. Your commitment to democratizing AI education aligns perfectly with our mission at CrewAI.\n",
            "\n",
            "At CrewAI, we specialize in developing AI-driven solutions that enhance online learning experiences. Our tools can provide deep insights into learner behaviors, enabling you to offer more personalized and effective educational programs. Moreover, our collaboration could further innovate your platforms, making AI education even more accessible and impactful across the globe.\n",
            "\n",
            "I would love the opportunity to discuss how our solutions could support DeepLearningAI's goals and contribute to the future of AI education. Are you available for a brief call next week to explore this potential partnership?\n",
            "\n",
            "Looking forward to your thoughts.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Lead Sales Representative, CrewAI\n",
            "\n",
            "\u001b[00m\n"
          ]
        }
      ],
      "source": [
        "inputs = {\n",
        "    \"lead_name\": \"DeepLearningAI\",\n",
        "    \"industry\": \"Online Learning Platform\",\n",
        "    \"key_decision_maker\": \"Andrew Ng\",\n",
        "    \"position\": \"CEO\",\n",
        "    \"milestone\": \"product launch\"\n",
        "}\n",
        "\n",
        "result = crew.kickoff(inputs=inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9ljijCSWrbQ"
      },
      "source": [
        "- Display the final result as Markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "DdeD-TOhWrbQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "9b922126-3edd-4389-a096-3d67dd4eb287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Subject: Empowering DeepLearningAI's Mission through Innovative AI Solutions\n\nDear Andrew,\n\nI hope this message finds you well. I'm reaching out to celebrate DeepLearningAI's recent successes in launching the new Machine Learning Specialization and updated courses in collaboration with tech leaders like Google and AWS. Your commitment to democratizing AI education aligns perfectly with our mission at CrewAI.\n\nAt CrewAI, we specialize in developing AI-driven solutions that enhance online learning experiences. Our tools can provide deep insights into learner behaviors, enabling you to offer more personalized and effective educational programs. Moreover, our collaboration could further innovate your platforms, making AI education even more accessible and impactful across the globe.\n\nI would love the opportunity to discuss how our solutions could support DeepLearningAI's goals and contribute to the future of AI education. Are you available for a brief call next week to explore this potential partnership?\n\nLooking forward to your thoughts.\n\nBest regards,\n[Your Name]\nLead Sales Representative, CrewAI"
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "x0TJWQk9WrbQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "This notebook demonstrates how to automate a customer outreach campaign using a multi-agent system, ensuring personalized and strategic communications to high-value leads. ​"
      ],
      "metadata": {
        "id": "0AqXqGAjxZAs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "cbWTJyeuWrbQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}